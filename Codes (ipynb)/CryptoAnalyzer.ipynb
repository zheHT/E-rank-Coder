{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50UDg6pOy4XL"
      },
      "outputs": [],
      "source": [
        "# Install any necessary library for this Machine Learning Model\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from hmmlearn import hmm\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTAhMhj22kyP"
      },
      "outputs": [],
      "source": [
        "class DataRetriever: #class to handle data retrieving using API key and data storing\n",
        "\n",
        "    def __init__(self, api_key, base_url=\"https://api.datasource.cybotrade.rs\"):\n",
        "\n",
        "        self.api_key = api_key\n",
        "        self.base_url = base_url\n",
        "        self.headers = {\n",
        "            \"X-API-KEY\": self.api_key\n",
        "        }\n",
        "\n",
        "    def fetch_data_and_save_csv(self, endpoint, params, csv_filename):\n",
        "        # conenct to server and save the retrieved data into a csv file\n",
        "        url = f\"{self.base_url}{endpoint}\"\n",
        "        try:\n",
        "            response = requests.get(url, headers=self.headers, params=params)\n",
        "            response.raise_for_status()  # Raise an exception for bad status codes\n",
        "            json_data = response.json()\n",
        "            if 'data' in json_data:\n",
        "                df = pd.DataFrame(json_data['data'])\n",
        "                try:\n",
        "                    df.to_csv(csv_filename, index=False)\n",
        "                    print(f\"Data successfully saved to {csv_filename}\")\n",
        "                    return True\n",
        "                except Exception as e:\n",
        "                    print(f\"Error saving to CSV: {e}\")\n",
        "                    return False\n",
        "            else:\n",
        "                print(f\"Error: 'data' key not found in the response for endpoint: {endpoint}\")\n",
        "                print(json_data)\n",
        "                return False\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error fetching data from {url}: {e}\")\n",
        "            return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgfd8pROG9_d"
      },
      "outputs": [],
      "source": [
        "class DataProcessor:\n",
        "\n",
        "  def __init__(self, csv_filepath):\n",
        "      self.csv_filepath = csv_filepath\n",
        "      self.df = None\n",
        "\n",
        "  def load_data(self): # function that reads the csv file and load data into df\n",
        "        try:\n",
        "            df = pd.read_csv(self.csv_filepath)\n",
        "            print(f\"Successfully loaded data from {self.csv_filepath}\")\n",
        "            print(f\"Initial DataFrame shape: {df.shape}\")\n",
        "            print(df.head())\n",
        "            print(df.info())\n",
        "            self.df = df\n",
        "            return df\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: The file '{self.csv_filepath}' was not found.\")\n",
        "            return None\n",
        "\n",
        "  def clean_data(self): # function to handle data conversion or data cleaning such as checking for missing value \n",
        "        if self.df is None:\n",
        "            print(\"Error: No data loaded. Cannot clean.\")\n",
        "            return None\n",
        "\n",
        "        print(\"\\n--- Checking for Missing Values ---\")\n",
        "        print(self.df.isnull().sum())\n",
        "\n",
        "        # Handle missing values (replace with your strategy)\n",
        "        self.df.fillna(0, inplace=True)\n",
        "        print(\"\\nMissing Values After Handling:\")\n",
        "        print(self.df.isnull().sum())\n",
        "\n",
        "        print(\"\\n--- Data Type Conversion ---\")\n",
        "        if 'time' in self.df.columns:  # Check for 'time' column\n",
        "            try:\n",
        "                self.df['timestamp'] = pd.to_datetime(self.df['time'], unit='s')  # Assuming 'time' is in seconds\n",
        "                self.df.drop('time', axis=1, inplace=True)\n",
        "                print(\"'time' converted to 'timestamp'.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error converting 'time': {e}\")\n",
        "        elif 'start_time' in self.df.columns:  # Fallback for 'start_time' if it exists\n",
        "            try:\n",
        "                self.df['timestamp'] = pd.to_datetime(self.df['start_time'], unit='ms')\n",
        "                self.df.drop('start_time', axis=1, inplace=True)\n",
        "                print(\"'start_time' converted to 'timestamp'.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error converting 'start_time': {e}\")\n",
        "        else:\n",
        "            print(\"Warning: Neither 'start_time' nor 'time' column found for timestamp conversion.\")\n",
        "\n",
        "        print(\"\\n--- Handling Duplicate Data ---\")\n",
        "        print(f\"Number of duplicate rows: {self.df.duplicated().sum()}\")\n",
        "        self.df.drop_duplicates(inplace=True)\n",
        "        print(f\"Number of rows after removing duplicates: {self.df.shape[0]}\")\n",
        "\n",
        "        return self.df\n",
        "\n",
        "  def preprocess_data(self): # function that calculate and add features to dataframe\n",
        "\n",
        "        if self.df is None:\n",
        "            print(\"Error: No data loaded. Cannot preprocess.\")\n",
        "            return None\n",
        "\n",
        "        print(\"\\n--- Feature Engineering ---\")\n",
        "        if 'bidsAmount' in self.df.columns and 'asksAmount' in self.df.columns: # calculate bid to ask ratio\n",
        "            self.df['bids_asks_ratio_amount'] = self.df['bidsAmount'] / (self.df['asksAmount'] + 1e-8)\n",
        "            print(\"Added 'bids_asks_ratio_amount' feature.\")\n",
        "\n",
        "        if 'bidsUsd' in self.df.columns and 'asksUsd' in self.df.columns: # calculate bid (USD) to ask (USD) ratio\n",
        "            self.df['bids_asks_ratio_usd'] = self.df['bidsUsd'] / (self.df['asksUsd'] + 1e-8)\n",
        "            print(\"Added 'bids_asks_ratio_usd' feature.\")\n",
        "\n",
        "        print(\"\\n--- Sorting and Indexing ---\")\n",
        "        if 'timestamp' in self.df.columns:\n",
        "            self.df.sort_values('timestamp', inplace=True)\n",
        "            self.df.set_index('timestamp', inplace=True)\n",
        "            print(\"Sorted by 'timestamp' and set as index.\")\n",
        "        else:\n",
        "            print(\"Warning: 'timestamp' column not found.\")\n",
        "\n",
        "        return self.df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNdL1Lw-HSiM"
      },
      "outputs": [],
      "source": [
        "class HMMTrader: # class to mainly handle HMM Model Training\n",
        "    \"\"\"\n",
        "        Trains the Hidden Markov Model.\n",
        "\n",
        "        Args:\n",
        "            df (pd.DataFrame): The processed DataFrame containing the features.\n",
        "            feature_columns (list): A list of column names to use as features for the HMM.\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: The DataFrame with the predicted HMM states added.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_components=5):\n",
        "\n",
        "        self.n_components = n_components\n",
        "        self.model = None\n",
        "        self.scaler = None\n",
        "        self.feature_columns = None\n",
        "\n",
        "    def train_hmm(self, df, feature_columns):\n",
        "\n",
        "        if df is None or df.empty or not all(col in df.columns for col in feature_columns):\n",
        "            print(\"Error: Invalid DataFrame or missing feature columns for HMM training.\")\n",
        "            return df\n",
        "\n",
        "        self.feature_columns = feature_columns\n",
        "        data = df[self.feature_columns].values\n",
        "\n",
        "        # Scale the data\n",
        "        self.scaler = MinMaxScaler()\n",
        "        scaled_data = self.scaler.fit_transform(data)\n",
        "\n",
        "        # Train the HMM\n",
        "        self.model = hmm.GaussianHMM(n_components=self.n_components, covariance_type=\"full\", n_iter=1000, random_state=42) # Added random_state for reproducibility\n",
        "        self.model.fit(scaled_data)\n",
        "\n",
        "        # Predict the hidden states\n",
        "        hidden_states = self.model.predict(scaled_data)\n",
        "        df['hmm_state'] = hidden_states\n",
        "\n",
        "        print(\"\\nHMM model trained successfully. Predicted states added to DataFrame.\")\n",
        "        return df\n",
        "\n",
        "    def save_state_to_csv(self, df_with_states, filename=\"hmm_states.csv\"):\n",
        "\n",
        "        if df_with_states is not None and 'hmm_state' in df_with_states.columns:\n",
        "            try:\n",
        "                df_with_states.to_csv(filename, index=True)  # Include index (timestamp if set)\n",
        "                print(f\"HMM states saved to {filename}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error saving HMM states to CSV: {e}\")\n",
        "        else:\n",
        "            print(\"Error: DataFrame with HMM states is None or 'hmm_state' column not found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJ160ztLHYyY"
      },
      "outputs": [],
      "source": [
        "class MainApp: # class to handle operations such as calling functions from other classes\n",
        "    def __init__(self, api_key, csv_filepath, n_hmm_components=3, hmm_features=['bids_asks_ratio_amount', 'bids_asks_ratio_usd']):\n",
        "        self.data_retriever = DataRetriever(api_key)\n",
        "        self.data_processor = DataProcessor(csv_filepath)\n",
        "        self.hmm_trader = HMMTrader(n_components=n_hmm_components)  # Instantiate HMMTrader\n",
        "        self.hmm_features = hmm_features  # Define the features for HMM\n",
        "        self.trained_df_with_states = None\n",
        "\n",
        "    def run(self):\n",
        "        endpoint = \"/coinglass/spot/orderbook/history\"\n",
        "        params = {\n",
        "            \"exchange\": \"Binance\",\n",
        "            \"symbol\": \"BTCUSDT\",\n",
        "            \"interval\": \"1h\",\n",
        "            \"start_time\": \"20191001T100000\",\n",
        "            \"limit\": 10000\n",
        "        }\n",
        "        csv_filename = \"coinglass_orderbook_history.csv\"\n",
        "        hmm_output_filename = \"hmm_states_output.csv\"\n",
        "\n",
        "        # 1. Retrieve data and save to CSV\n",
        "        if self.data_retriever.fetch_data_and_save_csv(endpoint, params, csv_filename):\n",
        "            # 2. Load data from the CSV\n",
        "            self.data_processor.load_data()\n",
        "            cleaned_df = self.data_processor.clean_data()\n",
        "            if cleaned_df is not None:\n",
        "                # 3. Preprocess the cleaned data\n",
        "                processed_df = self.data_processor.preprocess_data()\n",
        "                if processed_df is not None:\n",
        "                    print(\"\\nFinal processed DataFrame:\")\n",
        "                    print(processed_df.head())\n",
        "                    # 4. Train HMM model\n",
        "                    self.trained_df_with_states = self.hmm_trader.train_hmm(processed_df.copy(), self.hmm_features)\n",
        "                    if self.trained_df_with_states is not None:\n",
        "                        print(\"\\nDataFrame with HMM states:\")\n",
        "                        print(self.trained_df_with_states.reset_index()[['timestamp'] + self.hmm_features + ['hmm_state']].head())\n",
        "                        # 5. Save States to csv\n",
        "                        self.hmm_trader.save_state_to_csv(self.trained_df_with_states, hmm_output_filename)\n",
        "                    else:\n",
        "                        print(\"HMM training failed.\")\n",
        "                else:\n",
        "                    print(\"Data preprocessing failed. Cannot proceed with HMM training.\")\n",
        "            else:\n",
        "                print(\"Data cleaning failed. Cannot proceed with processing.\")\n",
        "        else:\n",
        "            print(\"Data retrieval failed. Cannot proceed with data loading.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBA7R8bzHa5O"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\": # passing api key and csv filename from main function\n",
        "    api_key = \"MKkf7j3pCKwrMOENp4JNKXWGK5JzYqI18jFKFcBUgxOMfHke\"\n",
        "    csv_filepath = \"coinglass_orderbook_history.csv\"\n",
        "    app = MainApp(api_key, csv_filepath)\n",
        "    app.run()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
