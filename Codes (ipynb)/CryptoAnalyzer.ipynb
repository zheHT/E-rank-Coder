{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "50UDg6pOy4XL"
      },
      "outputs": [],
      "source": [
        "# Install any necessary library for this Machine Learning Model\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from hmmlearn import hmm\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DataRetriever: #class to handle data retrieving using API key and data storing\n",
        "\n",
        "    def __init__(self, api_key, base_url=\"https://api.datasource.cybotrade.rs\"):\n",
        "\n",
        "        self.api_key = api_key\n",
        "        self.base_url = base_url\n",
        "        self.headers = {\n",
        "            \"X-API-KEY\": self.api_key\n",
        "        }\n",
        "\n",
        "    def fetch_data_and_save_csv(self, endpoint, params, csv_filename):\n",
        "        # conenct to server and save the retrieved data into a csv file\n",
        "        url = f\"{self.base_url}{endpoint}\"\n",
        "        try:\n",
        "            response = requests.get(url, headers=self.headers, params=params)\n",
        "            response.raise_for_status()  # Raise an exception for bad status codes\n",
        "            json_data = response.json()\n",
        "            if 'data' in json_data:\n",
        "                df = pd.DataFrame(json_data['data'])\n",
        "                try:\n",
        "                    df.to_csv(csv_filename, index=False)\n",
        "                    print(f\"Data successfully saved to {csv_filename}\")\n",
        "                    return True\n",
        "                except Exception as e:\n",
        "                    print(f\"Error saving to CSV: {e}\")\n",
        "                    return False\n",
        "            else:\n",
        "                print(f\"Error: 'data' key not found in the response for endpoint: {endpoint}\")\n",
        "                print(json_data)\n",
        "                return False\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error fetching data from {url}: {e}\")\n",
        "            return False"
      ],
      "metadata": {
        "id": "qTAhMhj22kyP"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataProcessor:\n",
        "\n",
        "  def __init__(self, csv_filepath):\n",
        "      self.csv_filepath = csv_filepath\n",
        "      self.df = None\n",
        "\n",
        "  def load_data(self): # function that reads the csv file and load data into df\n",
        "        try:\n",
        "            df = pd.read_csv(self.csv_filepath)\n",
        "            print(f\"Successfully loaded data from {self.csv_filepath}\")\n",
        "            print(f\"Initial DataFrame shape: {df.shape}\")\n",
        "            print(df.head())\n",
        "            print(df.info())\n",
        "            self.df = df\n",
        "            return df\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: The file '{self.csv_filepath}' was not found.\")\n",
        "            return None\n",
        "\n",
        "  def clean_data(self):\n",
        "        if self.df is None:\n",
        "            print(\"Error: No data loaded. Cannot clean.\")\n",
        "            return None\n",
        "\n",
        "        print(\"\\n--- Checking for Missing Values ---\")\n",
        "        print(self.df.isnull().sum())\n",
        "\n",
        "        # Handle missing values (replace with your strategy)\n",
        "        self.df.fillna(0, inplace=True)\n",
        "        print(\"\\nMissing Values After Handling:\")\n",
        "        print(self.df.isnull().sum())\n",
        "\n",
        "        print(\"\\n--- Data Type Conversion ---\")\n",
        "        if 'time' in self.df.columns:  # Check for 'time' column\n",
        "            try:\n",
        "                self.df['timestamp'] = pd.to_datetime(self.df['time'], unit='s')  # Assuming 'time' is in seconds\n",
        "                self.df.drop('time', axis=1, inplace=True)\n",
        "                print(\"'time' converted to 'timestamp'.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error converting 'time': {e}\")\n",
        "        elif 'start_time' in self.df.columns:  # Fallback for 'start_time' if it exists\n",
        "            try:\n",
        "                self.df['timestamp'] = pd.to_datetime(self.df['start_time'], unit='ms')\n",
        "                self.df.drop('start_time', axis=1, inplace=True)\n",
        "                print(\"'start_time' converted to 'timestamp'.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error converting 'start_time': {e}\")\n",
        "        else:\n",
        "            print(\"Warning: Neither 'start_time' nor 'time' column found for timestamp conversion.\")\n",
        "\n",
        "        print(\"\\n--- Handling Duplicate Data ---\")\n",
        "        print(f\"Number of duplicate rows: {self.df.duplicated().sum()}\")\n",
        "        self.df.drop_duplicates(inplace=True)\n",
        "        print(f\"Number of rows after removing duplicates: {self.df.shape[0]}\")\n",
        "\n",
        "        return self.df\n",
        "\n",
        "  def preprocess_data(self): # function that calculate and add features to dataframe\n",
        "\n",
        "        if self.df is None:\n",
        "            print(\"Error: No data loaded. Cannot preprocess.\")\n",
        "            return None\n",
        "\n",
        "        print(\"\\n--- Feature Engineering ---\")\n",
        "        if 'bidsAmount' in self.df.columns and 'asksAmount' in self.df.columns: # calculate bid to ask ratio\n",
        "            self.df['bids_asks_ratio_amount'] = self.df['bidsAmount'] / (self.df['asksAmount'] + 1e-8)\n",
        "            print(\"Added 'bids_asks_ratio_amount' feature.\")\n",
        "\n",
        "        if 'bidsUsd' in self.df.columns and 'asksUsd' in self.df.columns: # calculate bid (USD) to ask (USD) ratio\n",
        "            self.df['bids_asks_ratio_usd'] = self.df['bidsUsd'] / (self.df['asksUsd'] + 1e-8)\n",
        "            print(\"Added 'bids_asks_ratio_usd' feature.\")\n",
        "\n",
        "        print(\"\\n--- Sorting and Indexing ---\")\n",
        "        if 'timestamp' in self.df.columns:\n",
        "            self.df.sort_values('timestamp', inplace=True)\n",
        "            self.df.set_index('timestamp', inplace=True)\n",
        "            print(\"Sorted by 'timestamp' and set as index.\")\n",
        "        else:\n",
        "            print(\"Warning: 'timestamp' column not found.\")\n",
        "\n",
        "        return self.df"
      ],
      "metadata": {
        "id": "fgfd8pROG9_d"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HMMTrader:\n",
        "    \"\"\"\n",
        "        Trains the Hidden Markov Model.\n",
        "\n",
        "        Args:\n",
        "            df (pd.DataFrame): The processed DataFrame containing the features.\n",
        "            feature_columns (list): A list of column names to use as features for the HMM.\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: The DataFrame with the predicted HMM states added.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_components=5):\n",
        "\n",
        "        self.n_components = n_components\n",
        "        self.model = None\n",
        "        self.scaler = None\n",
        "        self.feature_columns = None\n",
        "\n",
        "    def train_hmm(self, df, feature_columns):\n",
        "\n",
        "        if df is None or df.empty or not all(col in df.columns for col in feature_columns):\n",
        "            print(\"Error: Invalid DataFrame or missing feature columns for HMM training.\")\n",
        "            return df\n",
        "\n",
        "        self.feature_columns = feature_columns\n",
        "        data = df[self.feature_columns].values\n",
        "\n",
        "        # Scale the data\n",
        "        self.scaler = MinMaxScaler()\n",
        "        scaled_data = self.scaler.fit_transform(data)\n",
        "\n",
        "        # Train the HMM\n",
        "        self.model = hmm.GaussianHMM(n_components=self.n_components, covariance_type=\"full\", n_iter=1000, random_state=42) # Added random_state for reproducibility\n",
        "        self.model.fit(scaled_data)\n",
        "\n",
        "        # Predict the hidden states\n",
        "        hidden_states = self.model.predict(scaled_data)\n",
        "        df['hmm_state'] = hidden_states\n",
        "\n",
        "        print(\"\\nHMM model trained successfully. Predicted states added to DataFrame.\")\n",
        "        return df\n",
        "\n",
        "    def save_state_to_csv(self, df_with_states, filename=\"hmm_states.csv\"):\n",
        "\n",
        "        if df_with_states is not None and 'hmm_state' in df_with_states.columns:\n",
        "            try:\n",
        "                df_with_states.to_csv(filename, index=True)  # Include index (timestamp if set)\n",
        "                print(f\"HMM states saved to {filename}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error saving HMM states to CSV: {e}\")\n",
        "        else:\n",
        "            print(\"Error: DataFrame with HMM states is None or 'hmm_state' column not found.\")"
      ],
      "metadata": {
        "id": "iNdL1Lw-HSiM"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MainApp: # class to handle operations such as calling functions from other classes\n",
        "    def __init__(self, api_key, csv_filepath, n_hmm_components=3, hmm_features=['bids_asks_ratio_amount', 'bids_asks_ratio_usd']):\n",
        "        self.data_retriever = DataRetriever(api_key)\n",
        "        self.data_processor = DataProcessor(csv_filepath)\n",
        "        self.hmm_trader = HMMTrader(n_components=n_hmm_components)  # Instantiate HMMTrader\n",
        "        self.hmm_features = hmm_features  # Define the features for HMM\n",
        "        self.trained_df_with_states = None\n",
        "\n",
        "    def run(self):\n",
        "        endpoint = \"/coinglass/spot/orderbook/history\"\n",
        "        params = {\n",
        "            \"exchange\": \"Binance\",\n",
        "            \"symbol\": \"BTCUSDT\",\n",
        "            \"interval\": \"1h\",\n",
        "            \"start_time\": \"20191001T100000\",\n",
        "            \"limit\": 10000\n",
        "        }\n",
        "        csv_filename = \"coinglass_orderbook_history.csv\"\n",
        "        hmm_output_filename = \"hmm_states_output.csv\"\n",
        "\n",
        "        # 1. Retrieve data and save to CSV\n",
        "        if self.data_retriever.fetch_data_and_save_csv(endpoint, params, csv_filename):\n",
        "            # 2. Load data from the CSV\n",
        "            self.data_processor.load_data()\n",
        "            cleaned_df = self.data_processor.clean_data()\n",
        "            if cleaned_df is not None:\n",
        "                # 3. Preprocess the cleaned data\n",
        "                processed_df = self.data_processor.preprocess_data()\n",
        "                if processed_df is not None:\n",
        "                    print(\"\\nFinal processed DataFrame:\")\n",
        "                    print(processed_df.head())\n",
        "                    # 4. Train HMM model\n",
        "                    self.trained_df_with_states = self.hmm_trader.train_hmm(processed_df.copy(), self.hmm_features)\n",
        "                    if self.trained_df_with_states is not None:\n",
        "                        print(\"\\nDataFrame with HMM states:\")\n",
        "                        print(self.trained_df_with_states.reset_index()[['timestamp'] + self.hmm_features + ['hmm_state']].head())\n",
        "                        # 5. Save States to csv\n",
        "                        self.hmm_trader.save_state_to_csv(self.trained_df_with_states, hmm_output_filename)\n",
        "                    else:\n",
        "                        print(\"HMM training failed.\")\n",
        "                else:\n",
        "                    print(\"Data preprocessing failed. Cannot proceed with HMM training.\")\n",
        "            else:\n",
        "                print(\"Data cleaning failed. Cannot proceed with processing.\")\n",
        "        else:\n",
        "            print(\"Data retrieval failed. Cannot proceed with data loading.\")"
      ],
      "metadata": {
        "id": "aJ160ztLHYyY"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\": # passing api key and csv filename from main function\n",
        "    api_key = \"MKkf7j3pCKwrMOENp4JNKXWGK5JzYqI18jFKFcBUgxOMfHke\"\n",
        "    csv_filepath = \"coinglass_orderbook_history.csv\"\n",
        "    app = MainApp(api_key, csv_filepath)\n",
        "    app.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBA7R8bzHa5O",
        "outputId": "dd1912ac-b8eb-4c88-83ff-55a969e596b1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:hmmlearn.base:Model is not converging.  Current: 165601.70235168512 is not greater than 165602.20352104882. Delta is -0.5011693637061398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully saved to coinglass_orderbook_history.csv\n",
            "Successfully loaded data from coinglass_orderbook_history.csv\n",
            "Initial DataFrame shape: (8464, 8)\n",
            "      start_time  asksAmount  asksRate       asksUsd  bidsAmount  bidsRate  \\\n",
            "0  1713942000000   330.30601    0.5785  2.213463e+07   242.38443    0.4215   \n",
            "1  1713945600000   308.14614    0.5146  2.061137e+07   293.20464    0.4854   \n",
            "2  1713949200000   260.83035    0.4805  1.742603e+07   284.68075    0.5195   \n",
            "3  1713952800000   249.18991    0.4008  1.659405e+07   375.42095    0.5992   \n",
            "4  1713956400000   254.66191    0.4282  1.698199e+07   342.85130    0.5718   \n",
            "\n",
            "        bidsUsd        time  \n",
            "0  1.612748e+07  1713942000  \n",
            "1  1.943848e+07  1713945600  \n",
            "2  1.884028e+07  1713949200  \n",
            "3  2.480784e+07  1713952800  \n",
            "4  2.267504e+07  1713956400  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8464 entries, 0 to 8463\n",
            "Data columns (total 8 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   start_time  8464 non-null   int64  \n",
            " 1   asksAmount  8464 non-null   float64\n",
            " 2   asksRate    8464 non-null   float64\n",
            " 3   asksUsd     8464 non-null   float64\n",
            " 4   bidsAmount  8464 non-null   float64\n",
            " 5   bidsRate    8464 non-null   float64\n",
            " 6   bidsUsd     8464 non-null   float64\n",
            " 7   time        8464 non-null   int64  \n",
            "dtypes: float64(6), int64(2)\n",
            "memory usage: 529.1 KB\n",
            "None\n",
            "\n",
            "--- Checking for Missing Values ---\n",
            "start_time    0\n",
            "asksAmount    0\n",
            "asksRate      0\n",
            "asksUsd       0\n",
            "bidsAmount    0\n",
            "bidsRate      0\n",
            "bidsUsd       0\n",
            "time          0\n",
            "dtype: int64\n",
            "\n",
            "Missing Values After Handling:\n",
            "start_time    0\n",
            "asksAmount    0\n",
            "asksRate      0\n",
            "asksUsd       0\n",
            "bidsAmount    0\n",
            "bidsRate      0\n",
            "bidsUsd       0\n",
            "time          0\n",
            "dtype: int64\n",
            "\n",
            "--- Data Type Conversion ---\n",
            "'time' converted to 'timestamp'.\n",
            "\n",
            "--- Handling Duplicate Data ---\n",
            "Number of duplicate rows: 0\n",
            "Number of rows after removing duplicates: 8464\n",
            "\n",
            "--- Feature Engineering ---\n",
            "Added 'bids_asks_ratio_amount' feature.\n",
            "Added 'bids_asks_ratio_usd' feature.\n",
            "\n",
            "--- Sorting and Indexing ---\n",
            "Sorted by 'timestamp' and set as index.\n",
            "\n",
            "Final processed DataFrame:\n",
            "                        start_time  asksAmount  asksRate       asksUsd  \\\n",
            "timestamp                                                                \n",
            "2024-04-24 07:00:00  1713942000000   330.30601    0.5785  2.213463e+07   \n",
            "2024-04-24 08:00:00  1713945600000   308.14614    0.5146  2.061137e+07   \n",
            "2024-04-24 09:00:00  1713949200000   260.83035    0.4805  1.742603e+07   \n",
            "2024-04-24 10:00:00  1713952800000   249.18991    0.4008  1.659405e+07   \n",
            "2024-04-24 11:00:00  1713956400000   254.66191    0.4282  1.698199e+07   \n",
            "\n",
            "                     bidsAmount  bidsRate       bidsUsd  \\\n",
            "timestamp                                                 \n",
            "2024-04-24 07:00:00   242.38443    0.4215  1.612748e+07   \n",
            "2024-04-24 08:00:00   293.20464    0.4854  1.943848e+07   \n",
            "2024-04-24 09:00:00   284.68075    0.5195  1.884028e+07   \n",
            "2024-04-24 10:00:00   375.42095    0.5992  2.480784e+07   \n",
            "2024-04-24 11:00:00   342.85130    0.5718  2.267504e+07   \n",
            "\n",
            "                     bids_asks_ratio_amount  bids_asks_ratio_usd  \n",
            "timestamp                                                         \n",
            "2024-04-24 07:00:00                0.733818             0.728609  \n",
            "2024-04-24 08:00:00                0.951512             0.943095  \n",
            "2024-04-24 09:00:00                1.091440             1.081157  \n",
            "2024-04-24 10:00:00                1.506566             1.494983  \n",
            "2024-04-24 11:00:00                1.346300             1.335240  \n",
            "\n",
            "HMM model trained successfully. Predicted states added to DataFrame.\n",
            "\n",
            "DataFrame with HMM states:\n",
            "            timestamp  bids_asks_ratio_amount  bids_asks_ratio_usd  hmm_state\n",
            "0 2024-04-24 07:00:00                0.733818             0.728609          0\n",
            "1 2024-04-24 08:00:00                0.951512             0.943095          0\n",
            "2 2024-04-24 09:00:00                1.091440             1.081157          0\n",
            "3 2024-04-24 10:00:00                1.506566             1.494983          0\n",
            "4 2024-04-24 11:00:00                1.346300             1.335240          0\n",
            "HMM states saved to hmm_states_output.csv\n"
          ]
        }
      ]
    }
  ]
}